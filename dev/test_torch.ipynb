{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¹¿æ’­\n",
    "\n",
    "ã€æˆ‘çš„ç†è§£ã€‘\n",
    "nç»´å¼ é‡A, Bçš„çŸ©é˜µä¹˜æ³•ï¼Œè¦æ±‚å‰é¢ n-2 ç»´éƒ½ç›¸ç­‰, æœ€å2ä¸ªç»´åº¦å¿…é¡»æ˜¯ (m, n), (n, k) çš„ç¬¦åˆçŸ©é˜µä¹˜æ³•çš„è¦æ±‚\n",
    " - ã€é”™è¯¯ç‚¹ã€‘å‰é¢çš„ç»´åº¦ï¼ˆå³ batch ç»´åº¦ï¼‰éœ€è¦æ»¡è¶³å¹¿æ’­ï¼ˆbroadcastingï¼‰è§„åˆ™ï¼Œè€Œä¸ä»…ä»…æ˜¯â€œå®Œå…¨ç›¸ç­‰â€ã€‚\n",
    "\n",
    "ã€ç†è§£2ã€‘å¹¿æ’­è§„åˆ™ï¼Œåˆ™å¯¹åº”çš„ç»´åº¦å¿…é¡»æ˜¯æ•´æ•°å€ï¼Œå¦åˆ™ä¸èƒ½å¹¿æ’­ï¼Ÿ\n",
    " - ã€é”™è¯¯ç‚¹ã€‘å¹¿æ’­çœ‹çš„æ˜¯â€œç›¸ç­‰æˆ–ä¸º1â€ï¼Œè€Œä¸æ˜¯â€œæ•´æ•°å€â€\n",
    "\n",
    "| æƒ…å†µ                   | èƒ½å¦å¹¿æ’­ï¼Ÿ | åŸå›                      |\n",
    "| -------------------- | ----- | ---------------------- |\n",
    "| `(3, 4)` vs `(3, 4)` | âœ…     | ç›¸ç­‰                     |\n",
    "| `(1, 4)` vs `(3, 4)` | âœ…     | 1 å¯æ‰©å±•                  |\n",
    "| `(2, 6)` vs `(3, 6)` | âŒ     | 2â‰ 3 ä¸”æ—  1               |\n",
    "| `(4, 5)` vs `(2, 5)` | âŒ     | 4â‰ 2 ä¸”æ—  1ï¼ˆå³ä½¿ 4 æ˜¯ 2 çš„å€æ•°ï¼‰ |\n",
    "\n",
    "\n",
    "ã€é—®é¢˜ã€‘ä¸ºä»€ä¹ˆä¸èƒ½ï¼Ÿ\n",
    "\n",
    "\n",
    "|ä½ çš„æƒ³æ³•|å®é™…è§„åˆ™|åŸå› |\n",
    "|---|---|---|\n",
    "|â€œ(2,5) é‡å¤ä¸€æ¬¡å˜ (4,5)â€|âŒ ä¸å…è®¸|å¹¿æ’­åªå…è®¸æ²¿ **size=1** çš„ç»´åº¦æ‹‰ä¼¸|\n",
    "|å¹¿æ’­ = ä»»æ„é‡å¤|âŒ|å¹¿æ’­ = **æ— æ­§ä¹‰ã€ç¡®å®šæ€§çš„è™šæ‹Ÿå¤åˆ¶**|\n",
    "|æ•´æ•°å€å°±èƒ½å¹¿æ’­|âŒ|å¿…é¡»æ»¡è¶³ï¼š**ç›¸ç­‰ æˆ– å…¶ä¸­ä¸€ä¸ªæ˜¯ 1**|\n",
    "\n",
    "> ğŸ’¡ **è®°ä½**ï¼šå¹¿æ’­æ˜¯ä¸ºäº†æ–¹ä¾¿â€œæ ‡é‡/å‘é‡/çŸ©é˜µâ€ä¸é«˜ç»´å¼ é‡è¿ç®—ï¼Œ**ä¸æ˜¯ä¸ºäº†ä»»æ„å½¢çŠ¶çš„è‡ªåŠ¨é€‚é…**ã€‚å½“éœ€è¦éæ ‡å‡†å¯¹é½æ—¶ï¼Œè¯·æ˜¾å¼ä½¿ç”¨ `repeat`ã€`expand`ã€`reshape` ç­‰æ“ä½œã€‚\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0204, -1.5683, -0.6974],\n",
      "        [ 1.2406,  0.5915,  0.8927]])\n",
      "tensor([[-2.0204, -1.5683, -0.6974],\n",
      "        [ 1.2406,  0.5915,  0.8927]])\n",
      "tensor([[-2.0204, -1.5683, -0.6974],\n",
      "        [ 1.2406,  0.5915,  0.8927]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "A = torch.randn(2, 3, 4)\n",
    "B = torch.randn(2, 4, 5)\n",
    "\n",
    "# æ–¹æ³•1: torch.einsum\n",
    "C1 = torch.einsum('bij,bjk->bi', A, B)  # å…ˆä¹˜å†å¯¹ k æ±‚å’Œ\n",
    "print(C1)\n",
    "\n",
    "# æ–¹æ³•2: einopsï¼ˆéœ€ç»„åˆï¼‰\n",
    "from einops import einsum\n",
    "C2 = einsum(A, B, 'b i j, b j k -> b i')  # einops ä¹Ÿæ”¯æŒ einsum!\n",
    "print(C2)\n",
    "\n",
    "# æ–¹æ³•3: åŸç”Ÿ\n",
    "C3 = (A @ B).sum(dim=-1)\n",
    "print(C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾‹å­1: æ‰¹é‡çŸ©é˜µä¹˜æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 4])\n",
      "torch.Size([10, 20, 4])\n",
      "torch.Size([10, 20, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "batch = 10\n",
    "seq_len = 20\n",
    "d_in = 5\n",
    "d_out = 4\n",
    "D = torch.randn(batch, seq_len, d_in)\n",
    "A = torch.randn(d_out, d_in)\n",
    "\n",
    "Y = D @ A.T\n",
    "\n",
    "assert Y.shape == (batch, seq_len, d_out)\n",
    "print(Y.shape)\n",
    "\n",
    "Y = einsum(D, A, \"batch seq_len d_in, d_out d_in -> batch seq_len d_out\")\n",
    "print(Y.shape)\n",
    "\n",
    "Y = einsum(D, A, \"... d_in, d_out d_in -> ... d_out\")\n",
    "print(Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾‹å­2ï¼šå¹¿æ’­æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([64, 10, 128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "\n",
    "images = torch.randn(64, 128, 128, 3) # (batch, height, width, channel)\n",
    "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)\n",
    "\n",
    "## Reshape and multiply  \n",
    "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")  \n",
    "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")  \n",
    "dimmed_images = images_rearr * dim_value\n",
    "\n",
    "## Or in one go:\n",
    "dimmed_images2 = einsum(\n",
    "    images, dim_by,\n",
    "    \"batch height width channel, dim_value -> batch dim_value height width channel\"\n",
    ")\n",
    "\n",
    "print(torch.equal(dimmed_images, dimmed_images2))\n",
    "print(dimmed_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾‹å­3ï¼šåƒç´ æ··åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç´¢å¼•\n",
    "\n",
    "PyTorch æ”¯æŒå¤šç§ç´¢å¼•æ–¹å¼ï¼Œä¸»è¦åŒ…æ‹¬ï¼š\n",
    "\n",
    "1. **åŸºæœ¬åˆ‡ç‰‡ï¼ˆBasic Slicingï¼‰**\n",
    "    - ä½¿ç”¨ `:`ã€æ•´æ•°ã€`...` ç­‰ã€‚\n",
    "    - è¿”å›çš„æ˜¯åŸå¼ é‡çš„**è§†å›¾ï¼ˆviewï¼‰**ï¼Œä¸å¤åˆ¶æ•°æ®ã€‚\n",
    "    - ä¾‹å¦‚ï¼š`t[0]`, `t[:, 1:3]`\n",
    "2. **é«˜çº§ç´¢å¼•ï¼ˆAdvanced Indexingï¼‰**\n",
    "    - ä½¿ç”¨ **æ•´æ•°åˆ—è¡¨/æ•°ç»„** æˆ– **å¸ƒå°”æ©ç **ã€‚\n",
    "    - è¿”å›çš„æ˜¯**æ–°å¼ é‡ï¼ˆå‰¯æœ¬ï¼‰**ï¼Œä¼šå¤åˆ¶æ•°æ®ã€‚\n",
    "    - ä¾‹å¦‚ï¼š`t[[0, 2]]`, `t[torch.tensor([0,2])]`\n",
    "\n",
    "> âš ï¸ æ³¨æ„ï¼šå½“ä½ ç”¨ `torch.LongTensor([0, 2])` è¿™æ ·çš„å¼ é‡ä½œä¸ºç´¢å¼•æ—¶ï¼Œå°±è¿›å…¥äº†**é«˜çº§ç´¢å¼•**çš„èŒƒç•´ã€‚\n",
    "\n",
    "`indices` æ˜¯ä¸€ä¸ªä¸€ç»´ LongTensorï¼ŒPyTorch é»˜è®¤å°†å…¶ç”¨äºç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆdim=0ï¼‰ã€‚\n",
    "æ‰€ä»¥å®ƒä¼šå–å‡ºç¬¬ 0 è¡Œå’Œç¬¬ 2 è¡Œã€‚\n",
    "\n",
    "ğŸ“Œ **å…³é”®ç‚¹**ï¼š`t1[indices]` å®é™…ä¸Šæ˜¯ `t1[indices, :]` çš„ç®€å†™ï¼ˆçœç•¥äº†åé¢çš„ `:`ï¼‰ã€‚\n",
    "\n",
    "æ³¨æ„ï¼š\n",
    "\n",
    "- `t1[indices]` æ˜¯ Python çš„ `__getitem__` è¯­æ³•ç³–ï¼Œæ›´ç®€æ´ã€‚\n",
    "- `index_select` æ›´**æ˜¾å¼ã€å®‰å…¨ã€å¯è¯»æ€§å¼º**ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯ä¸­æ¨èä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  2],\n",
      "        [ 4,  6],\n",
      "        [ 8, 10]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  2],\n",
      "        [ 4,  6],\n",
      "        [ 8, 10]])\n",
      "tensor([ 0, 10])\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.arange(12).reshape((3, 4))\n",
    "indices = torch.LongTensor([0, 2])\n",
    "\n",
    "print(t1[indices])\n",
    "print(t1[:, indices])\n",
    "print(torch.index_select(t1, 0, indices))\n",
    "print(torch.index_select(t1, 1, indices))\n",
    "\n",
    "# ä½†æ³¨æ„ï¼šä¸èƒ½ç›´æ¥å†™ t1[indices, indices]ï¼\n",
    "# å› ä¸ºè¿™ä¼šè§¦å‘â€œå¹¿æ’­å¼é«˜çº§ç´¢å¼•â€ï¼Œç»“æœæ˜¯ (2,) è€Œä¸æ˜¯ (2,2)\n",
    "print(t1[indices, indices])  # è¾“å‡º:  â† åªå– (0,0) å’Œ (2,2)\n",
    "print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 8,  9, 10, 11]]) torch.Size([5, 4])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 8,  9, 10, 11]]) torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "res = t1[[1, 0, 1, 2, 2]]\n",
    "print(res, res.shape)\n",
    "res = t1[[1, 0, 1, 2, 2],:]  # ç­‰ä»·è¡¨è¾¾å¼, ä»ç¬¬0ç»´ é€‰æ‹©å¤šä¸ªè¡Œ\n",
    "print(res, res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]]) t1\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[ 0,  1,  2,  3],\n",
      "         [ 8,  9, 10, 11]]]) torch.Size([2, 2, 4])\n",
      "tensor([[0, 9],\n",
      "        [0, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(t1, \"t1\")\n",
    "idx2 = torch.LongTensor([[0, 2], [0, 2]])\n",
    "res2 = t1[idx2]\n",
    "print(res2, res2.shape)\n",
    "print(torch.gather(t1, dim=0, index=idx2))\n",
    "# take_along_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™æ˜¯ä¸€ä¸ªéå¸¸ç»å…¸çš„Â **é«˜çº§ç´¢å¼•ï¼ˆAdvanced Indexingï¼‰**Â æ¡ˆä¾‹ã€‚åœ¨ 2026 å¹´çš„ PyTorch ç‰ˆæœ¬ä¸­ï¼Œå…¶é€»è¾‘ä¾ç„¶éµå¾ª NumPy çš„å¹¿æ’­è§„åˆ™ã€‚\n",
    "\n",
    "ä¸ºä»€ä¹ˆç»“æœæ˜¯Â `[2, 2, 4]`ï¼Ÿ\n",
    "\n",
    "å½“ä½ å¯¹ä¸€ä¸ª 2D å¼ é‡Â `t1`Â ä½¿ç”¨ä¸€ä¸ª 2D ç´¢å¼•å¼ é‡Â `idx2`Â æ—¶ï¼ŒPyTorch çš„å¤„ç†é€»è¾‘å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. **ç´¢å¼•å±‚çº§å®šä½**ï¼šä½ åªæä¾›äº†ä¸€ä¸ªç´¢å¼•å¼ é‡Â `idx2`ï¼Œå› æ­¤ PyTorch å°†å…¶ä½œç”¨äºÂ `t1`Â çš„**ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆDim 0ï¼Œå³â€œè¡Œâ€ï¼‰**Â [1]ã€‚\n",
    "2. **å½¢çŠ¶æ˜ å°„**ï¼š\n",
    "    - `t1`Â çš„å½¢çŠ¶æ˜¯Â `(3, 4)`ã€‚å…¶ä¸­Â `dim 0`Â å¤§å°ä¸º 3ï¼Œ`dim 1`Â å¤§å°ä¸º 4ã€‚\n",
    "    - `idx2`Â çš„å½¢çŠ¶æ˜¯Â `(2, 2)`ã€‚\n",
    "3. **å…ƒç´ æ›¿æ¢**ï¼š\n",
    "    - PyTorch ä¼šéå†Â `idx2`Â ä¸­çš„æ¯ä¸€ä¸ªå€¼ï¼Œå°†å…¶æ›¿æ¢ä¸ºÂ `t1`Â ä¸­å¯¹åº”çš„â€œè¡Œâ€ã€‚\n",
    "    - `idx2`Â ä¸­çš„å…ƒç´ æ˜¯Â `0`Â å’ŒÂ `2`ã€‚åœ¨Â `t1`Â ä¸­ï¼Œç¬¬ 0 è¡Œæ˜¯Â `[0, 1, 2, 3]`ï¼Œç¬¬ 2 è¡Œæ˜¯Â `[8, 9, 10, 11]`ã€‚\n",
    "4. **æœ€ç»ˆå½¢çŠ¶è®¡ç®—**ï¼š\n",
    "    - ç»“æœçš„å‰ä¸¤ä¸ªç»´åº¦ç”±Â **ç´¢å¼•å¼ é‡Â `idx2`Â çš„å½¢çŠ¶**Â å†³å®šï¼š`(2, 2)`ã€‚\n",
    "    - ç»“æœçš„å‰©ä½™ç»´åº¦ç”±Â **è¢«ç´¢å¼•å¼ é‡Â `t1`Â å‰©ä½™çš„ç»´åº¦**Â å†³å®šï¼š`(4,)`ã€‚\n",
    "    - å› æ­¤ï¼Œæœ€ç»ˆå½¢çŠ¶ä¸ºÂ `(2, 2, 4)`ã€‚\n",
    "\n",
    "å†…éƒ¨å¯¹åº”å…³ç³»æ‹†è§£ï¼š\n",
    "\n",
    "- `res2[0, 0]`Â å¯¹åº”Â `t1[idx2[0, 0]]`Â ->Â `t1[0]`Â ->Â `[0, 1, 2, 3]`\n",
    "- `res2[0, 1]`Â å¯¹åº”Â `t1[idx2[0, 1]]`Â ->Â `t1[2]`Â ->Â `[8, 9, 10, 11]`\n",
    "- `res2[1, 0]`Â å¯¹åº”Â `t1[idx2[1, 0]]`Â ->Â `t1[0]`Â ->Â `[0, 1, 2, 3]`\n",
    "- `res2[1, 1]`Â å¯¹åº”Â `t1[idx2[1, 1]]`Â ->Â `t1[2]`Â ->Â `[8, 9, 10, 11]`\n",
    "\n",
    "å¦‚æœä½ æƒ³å¾—åˆ°Â `(2, 2)`Â è€Œä¸æ˜¯Â `(2, 2, 4)`Â æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "å¦‚æœä½ å¸Œæœ›ç»“æœç›´æ¥å®šä½åˆ°å…·ä½“çš„æ ‡é‡å…ƒç´ ï¼Œä½ éœ€è¦åŒæ—¶æä¾›Â **Dim 1ï¼ˆåˆ—ï¼‰**Â çš„ç´¢å¼•ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³åœ¨Â `t1`Â ä¸­æ ¹æ®Â `idx2`Â æå–ç‰¹å®šçš„å…ƒç´ ï¼Œä½ éœ€è¦è®©ç´¢å¼•å¼ é‡çš„å½¢çŠ¶åŒ¹é…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 10],\n",
      "        [ 0, 10]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# å‡è®¾æˆ‘ä»¬è¦æå– (0,0), (2,2) å’Œ (0,0), (2,2) ä½ç½®çš„å››ä¸ªå…ƒç´ \n",
    "row_idx = torch.LongTensor([[0, 2], [0, 2]])\n",
    "col_idx = torch.LongTensor([[0, 2], [0, 2]])\n",
    "\n",
    "res = t1[row_idx, col_idx] \n",
    "print(res, res.shape) # è¾“å‡º torch.Size([2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Dimensions (Coordinate Indexing): When multiple integer index tensors are provided, they broadcast together to form a set of coordinates. The resulting tensor's shape will be the broadcasted shape of the index tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 11])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "# x:\n",
    "# tensor([[ 0,  1,  2,  3],\n",
    "#         [ 4,  5,  6,  7],\n",
    "#         [ 8,  9, 10, 11]])\n",
    "\n",
    "rows = torch.tensor([0, 2])\n",
    "cols = torch.tensor([1, 3])\n",
    "# Select elements at (0, 1) and (2, 3)\n",
    "selected = x[rows, cols]\n",
    "# selected is tensor([1, 11])\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Tensor Indexing\n",
    "\n",
    "You can use a BoolTensor as a mask to select elements corresponding to True values. \n",
    " - The boolean tensor must have the same shape as the original tensor (or be broadcastable) in the dimensions being masked. The output is a 1D tensor containing all the selected elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).reshape(2, 2)\n",
    "# x:\n",
    "# tensor([[0, 1],\n",
    "#         [2, 3]])\n",
    "\n",
    "mask = torch.tensor([[True, False], [False, True]])\n",
    "selected = x[mask]\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4119, -0.4434,  0.4310],\n",
      "        [ 0.3909, -0.2405,  0.0515]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones((2, 3))\n",
    "torch.nn.init.trunc_normal_(t1, a=-0.5, b=0.5)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.tensor(9.0)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "weight1 = torch.randn(2, 3)\n",
    "print(weight1.requires_grad)\n",
    "\n",
    "weight2 = nn.Parameter(torch.randn(2, 3))\n",
    "print(weight2.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹ é¢˜ï¼šé«˜çº§ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_ids torch.Size([40])\n",
      "flat_ids torch.Size([4])\n",
      "å¼‚å¸¸index token idï¼ŒæŠ›å¼‚å¸¸ç¬¦åˆè¡Œä¸ºã€‚ index out of range in self\n",
      "âœ… æ­å–œï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ‚¨å·²æŒæ¡é«˜çº§ç´¢å¼•ç²¾é«“\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NaiveEmbedding(nn.Module):\n",
    "    \"\"\"ç¹çå†™æ³•ï¼šä½¿ç”¨ index_select + reshape\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embed_matrix = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "    \n",
    "    def forward(self, token_ids):\n",
    "        # TODO: å®ç° index_select çš„ç¹çå†™æ³•ï¼ˆ4æ­¥ï¼‰\n",
    "        # 1. ä¿å­˜åŸå§‹å½¢çŠ¶ï¼ˆé™¤æœ€åä¸€ç»´å¤–ï¼‰\n",
    "        original_shape = token_ids.shape\n",
    "        \n",
    "        # 2. å°† token_ids å±•å¹³ä¸º 1D\n",
    "        flat_ids = token_ids.reshape(-1)\n",
    "        print(\"flat_ids\", flat_ids.shape)\n",
    "        \n",
    "        # 3. ä½¿ç”¨ index_select æå–å‘é‡ï¼ˆæ³¨æ„ï¼šindex_select è¦æ±‚ç´¢å¼•ä¸º1Dï¼‰\n",
    "        flat_embeds = torch.index_select(self.embed_matrix, 0, flat_ids)\n",
    "        \n",
    "        # 4. æ¢å¤å½¢çŠ¶ï¼šåŸå§‹å½¢çŠ¶ + (embed_dim,)\n",
    "        new_shape = original_shape + (flat_embeds.shape[-1], )\n",
    "        return flat_embeds.reshape(new_shape) # â† ç”¨æˆ·å¡«å†™\n",
    "\n",
    "\n",
    "class OptimizedEmbedding(nn.Module):\n",
    "    \"\"\"ç®€æ´å†™æ³•ï¼šç›´æ¥ä½¿ç”¨é«˜çº§ç´¢å¼•\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embed_matrix = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "    \n",
    "    def forward(self, token_ids):\n",
    "        # TODO: ç”¨ä¸€è¡Œä»£ç å®ç° embedding lookup\n",
    "        return self.embed_matrix[token_ids]\n",
    "\n",
    "\n",
    "# ==================== æµ‹è¯•æ¡†æ¶ï¼ˆæœªå¡«å†™æ ¸å¿ƒé€»è¾‘æ—¶å¿…ç„¶å¤±è´¥ï¼‰ ====================\n",
    "def test_embedding_consistency():\n",
    "    vocab_size, embed_dim = 100, 64\n",
    "    naive_emb = NaiveEmbedding(vocab_size, embed_dim)\n",
    "    opt_emb = OptimizedEmbedding(vocab_size, embed_dim)\n",
    "    opt_emb.embed_matrix.data = naive_emb.embed_matrix.data.clone()\n",
    "    \n",
    "    # æµ‹è¯•1: 2D å¼ é‡ [batch, seq_len]\n",
    "    token_ids_2d = torch.randint(0, vocab_size, (4, 10))\n",
    "    \n",
    "    # æœªå¡«å†™æ—¶ï¼šnaive_emb è¿”å› None â†’ è§¦å‘ TypeError\n",
    "    naive_out = naive_emb(token_ids_2d)  # â† å¿…ç„¶å¤±è´¥ï¼ç”¨æˆ·éœ€å®ç°\n",
    "    opt_out = opt_emb(token_ids_2d)      # â† å¿…ç„¶å¤±è´¥ï¼ç”¨æˆ·éœ€å®ç°\n",
    "    \n",
    "    # ä»¥ä¸‹æ–­è¨€ä»…åœ¨ç”¨æˆ·æ­£ç¡®å®ç°åé€šè¿‡\n",
    "    assert naive_out is not None, \"âŒ NaiveEmbedding æœªå®ç°ï¼\"\n",
    "    assert opt_out is not None, \"âŒ OptimizedEmbedding æœªå®ç°ï¼\"\n",
    "    assert torch.allclose(naive_out, opt_out), \"âŒ è¾“å‡ºä¸ä¸€è‡´ï¼\"\n",
    "    assert opt_out.shape == (4, 10, embed_dim), f\"âŒ å½¢çŠ¶é”™è¯¯: {opt_out.shape}\"\n",
    "    \n",
    "    # æµ‹è¯•2: 3D å¼ é‡éªŒè¯å½¢çŠ¶ä¼ æ’­\n",
    "    token_ids_3d = torch.randint(0, vocab_size, (2, 5, 3))\n",
    "    output = opt_emb(token_ids_3d)\n",
    "    assert output.shape == (2, 5, 3, embed_dim), f\"âŒ 3Då½¢çŠ¶é”™è¯¯: {output.shape}\"\n",
    "    \n",
    "    # é™„åŠ æŒ‘æˆ˜ï¼šè´Ÿæ•°ç´¢å¼•ï¼ˆä»… OptimizedEmbedding æ”¯æŒï¼‰\n",
    "    neg_ids = torch.tensor([[-1, 0], [1, -2]])  # -1 è¡¨ç¤ºæœ€åä¸€ä¸ªå…ƒç´ \n",
    "    try:\n",
    "        naive_emb(neg_ids)  # åº”æŠ›å‡º RuntimeErrorï¼ˆindex_select ä¸æ”¯æŒè´Ÿç´¢å¼•ï¼‰\n",
    "        raise AssertionError(\"âŒ NaiveEmbedding åº”æ‹’ç»è´Ÿç´¢å¼•ï¼\")\n",
    "    except Exception as e:\n",
    "        print(\"å¼‚å¸¸index token idï¼ŒæŠ›å¼‚å¸¸ç¬¦åˆè¡Œä¸ºã€‚\", str(e))\n",
    "        pass  # é¢„æœŸè¡Œä¸º\n",
    "    \n",
    "    # OptimizedEmbedding åº”æ­£ç¡®å¤„ç†è´Ÿç´¢å¼•\n",
    "    neg_out = opt_emb(neg_ids)\n",
    "    assert neg_out.shape == (2, 2, embed_dim), \"âŒ è´Ÿç´¢å¼•è¾“å‡ºå½¢çŠ¶é”™è¯¯\"\n",
    "    # éªŒè¯ -1 ç¡®å®æŒ‡å‘æœ€åä¸€ä¸ªå…ƒç´ \n",
    "    assert torch.allclose(neg_out[0,0], opt_emb.embed_matrix[-1]), \"âŒ è´Ÿç´¢å¼•é€»è¾‘é”™è¯¯\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        test_embedding_consistency()\n",
    "        print(\"âœ… æ­å–œï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ‚¨å·²æŒæ¡é«˜çº§ç´¢å¼•ç²¾é«“\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc() \n",
    "        print(f\"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}: {e}\")\n",
    "        print(\"\\nğŸ’¡ æç¤ºï¼šè¯·å®Œæˆä»¥ä¸‹æ ¸å¿ƒå®ç°ï¼š\")\n",
    "        print(\"  1. NaiveEmbedding.forward() ä¸­çš„ 4 æ­¥ reshape + index_select\")\n",
    "        print(\"  2. OptimizedEmbedding.forward() ä¸­çš„å•è¡Œé«˜çº§ç´¢å¼•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keepdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022) torch.Size([])\n",
      "torch.Size([64, 128]) torch.Size([64, 128, 1])\n"
     ]
    }
   ],
   "source": [
    "images = torch.randn(64, 128, 3)\n",
    "res0 = torch.mean(images)\n",
    "res1 = torch.mean(images, dim=2)\n",
    "res2 = torch.mean(images, dim=2, keepdim=True)\n",
    "\n",
    "print(res0, res0.shape)\n",
    "print(res1.shape, res2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (128) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mres1\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (128) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "images - res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "print((images - res2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ropeç›¸å…³-range,åŠæ—‹è½¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "tensor(1.) tensor(0.0013)\n",
      "0.0013182567385564075\n",
      "torch.Size([25])\n",
      "tensor(-0.) tensor(-0.9600)\n"
     ]
    }
   ],
   "source": [
    "theta = 1000\n",
    "d_k = 50\n",
    "invert = theta ** (-torch.arange(0, d_k/2, 1)/(d_k/2))\n",
    "print(invert.shape)\n",
    "print(invert[0], invert[-1])\n",
    "print(1000 ** (-24/25))\n",
    "\n",
    "irange = -torch.arange(0, d_k/2, 1)/(d_k/2)\n",
    "print(irange.shape)\n",
    "print(irange[0], irange[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9900, -0.6480, -0.1549,  0.2583,  0.5458,  0.7293,  0.8410,  0.9074,\n",
       "         0.9464,  0.9690,  0.9821,  0.9897,  0.9941,  0.9966,  0.9980,  0.9989,\n",
       "         0.9993,  0.9996,  0.9998,  0.9999,  0.9999,  1.0000,  1.0000,  1.0000,\n",
       "         1.0000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(3 * invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "token_positions = torch.arange(seq_len)\n",
    "print(token_positions.shape)\n",
    "print(token_positions)\n",
    "token_positions = token_positions.unsqueeze(0)\n",
    "torch.unsqueeze\n",
    "print(token_positions.shape)\n",
    "print(token_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ è§‚å¯Ÿåˆ°çš„è¿™ä¸ªè¡Œä¸ºæ˜¯å®Œå…¨æ­£ç¡®çš„ï¼Œè¿™æ˜¯ PyTorch `torch.repeat_interleave()` å‡½æ•°çš„ä¸€ä¸ªç‰¹æ®Šé‡è½½ç‰ˆæœ¬çš„è¡Œä¸ºã€‚\n",
    "\n",
    "**è§£é‡Š**\n",
    "\n",
    "å½“ä½ è°ƒç”¨ `torch.repeat_interleave(arr)` åªä¼ å…¥ä¸€ä¸ªå‚æ•°æ—¶ï¼ŒPyTorch ä¼šè°ƒç”¨ä»¥ä¸‹é‡è½½ï¼š\n",
    "\n",
    "```python\n",
    "repeat_interleave(repeats, *, output_size=None) -> Tensor\n",
    "```\n",
    "\n",
    "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ**ä¼ å…¥çš„å¼ é‡è¢«è§£é‡Šä¸º `repeats`ï¼ˆé‡å¤æ¬¡æ•°ï¼‰å‚æ•°**ï¼Œè€Œä¸æ˜¯ `input`ï¼ˆè¾“å…¥å¼ é‡ï¼‰å‚æ•°ã€‚\n",
    "\n",
    "æ ¹æ® PyTorch å®˜æ–¹æ–‡æ¡£çš„è¯´æ˜ï¼š\n",
    "> \"If the `repeats` is `tensor([n1, n2, n3, ...])`, then the output will be `tensor([0, 0, ..., 1, 1, ..., 2, 2, ..., ...])` where `0` appears `n1` times, `1` appears `n2` times, `2` appears `n3` times, etc.\" \n",
    "\n",
    "**å…·ä½“åˆ†æä½ çš„ä¾‹å­**\n",
    "\n",
    "```python\n",
    "seq_len = 10\n",
    "arr = torch.arange(seq_len)  # tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "```\n",
    "\n",
    "å½“è°ƒç”¨ `torch.repeat_interleave(arr)` æ—¶ï¼š\n",
    "- `arr` è¢«å½“ä½œ `repeats` = `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n",
    "- è¾“å‡ºè§„åˆ™ï¼š**æ•°å­— 0 é‡å¤ 0 æ¬¡ï¼Œæ•°å­— 1 é‡å¤ 1 æ¬¡ï¼Œæ•°å­— 2 é‡å¤ 2 æ¬¡ï¼Œ...ï¼Œæ•°å­— 9 é‡å¤ 9 æ¬¡**\n",
    "\n",
    "æ‰€ä»¥è¾“å‡ºæ˜¯ï¼š\n",
    "```\n",
    "tensor([1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, \n",
    "        7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9])\n",
    "```\n",
    "\n",
    "éªŒè¯ï¼š\n",
    "- 0 å‡ºç° 0 æ¬¡ â†’ æ²¡æœ‰ 0\n",
    "- 1 å‡ºç° 1 æ¬¡ â†’ `[1]`\n",
    "- 2 å‡ºç° 2 æ¬¡ â†’ `[2, 2]`\n",
    "- 3 å‡ºç° 3 æ¬¡ â†’ `[3, 3, 3]`\n",
    "- ...\n",
    "- 9 å‡ºç° 9 æ¬¡ â†’ `[9, 9, 9, 9, 9, 9, 9, 9, 9]`\n",
    "\n",
    "\n",
    "è¿™ä¸ªå•å‚æ•°é‡è½½ç‰ˆæœ¬çš„è®¾è®¡æ˜¯ä¸ºäº†æ–¹ä¾¿ç”Ÿæˆç‰¹å®šæ¨¡å¼çš„åºåˆ—ï¼Œç±»ä¼¼äº `numpy.repeat` çš„æŸäº›ç”¨æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7,\n",
       "        7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 10\n",
    "arr = torch.arange(seq_len)\n",
    "torch.repeat_interleave(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(arr, repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3],\n",
       "        [ 4,  4,  4,  5,  5,  5,  6,  6,  6,  7,  7,  7],\n",
       "        [ 8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.arange(12).reshape((3, 4))\n",
    "\n",
    "torch.repeat_interleave(arr, repeats=3, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  4,  8, 12]),\n",
       " tensor([ 1,  5,  9, 13]),\n",
       " tensor([ 2,  6, 10, 14]),\n",
       " tensor([ 3,  7, 11, 15]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.arange(16).reshape((4, 4))\n",
    "arr.unbind(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]),\n",
       " tensor([4, 5, 6, 7]),\n",
       " tensor([ 8,  9, 10, 11]),\n",
       " tensor([12, 13, 14, 15]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.unbind(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2]])\n",
      "tensor([[3, 4, 5]])\n",
      "tensor([[[-3,  0],\n",
      "         [-4,  1],\n",
      "         [-5,  2]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3,  0, -4,  1, -5,  2]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import einops\n",
    "x1 = torch.arange(3).reshape((1, 3))\n",
    "x2 = x1 + 3\n",
    "print(x1)\n",
    "print(x2)\n",
    "res = torch.stack((-x2, x1), dim=-1)\n",
    "print(res)\n",
    "einops.rearrange(res, \"... d j -> ... (d j)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "tensor([[-1,  0],\n",
      "        [-3,  2],\n",
      "        [-5,  4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1,  0, -3,  2, -5,  4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import einops\n",
    "x0 = torch.arange(6)\n",
    "print(x0)\n",
    "x = einops.rearrange(x0, \"... (d j) -> ... d j\", j=2)\n",
    "print(x)\n",
    "x1, x2 = x.unbind(dim=-1)\n",
    "\n",
    "res = torch.stack((-x2, x1), dim=-1)\n",
    "print(res)\n",
    "einops.rearrange(res, \"... d j -> ... (d j)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[[ 6,  7,  8]],\n",
       "\n",
       "        [[15, 16, 17]],\n",
       "\n",
       "        [[24, 25, 26]]]),\n",
       "indices=tensor([[[2, 2, 2]],\n",
       "\n",
       "        [[2, 2, 2]],\n",
       "\n",
       "        [[2, 2, 2]]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.arange(27).reshape((3, 3, 3))\n",
    "torch.max(arr, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 6,  7,  8]],\n",
      "\n",
      "        [[15, 16, 17]],\n",
      "\n",
      "        [[24, 25, 26]]])\n",
      "torch.Size([3, 1, 3])\n",
      "tensor([[[-6, -6, -6],\n",
      "         [-3, -3, -3],\n",
      "         [ 0,  0,  0]],\n",
      "\n",
      "        [[-6, -6, -6],\n",
      "         [-3, -3, -3],\n",
      "         [ 0,  0,  0]],\n",
      "\n",
      "        [[-6, -6, -6],\n",
      "         [-3, -3, -3],\n",
      "         [ 0,  0,  0]]])\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "arr_max = torch.max(arr, dim=1, keepdim=True).values\n",
    "print(arr_max)\n",
    "print(arr_max.shape)\n",
    "diff = arr - arr_max\n",
    "print(diff)\n",
    "print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0025, 0.0025, 0.0025],\n",
      "         [0.0498, 0.0498, 0.0498],\n",
      "         [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.0025, 0.0025, 0.0025],\n",
      "         [0.0498, 0.0498, 0.0498],\n",
      "         [1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.0025, 0.0025, 0.0025],\n",
      "         [0.0498, 0.0498, 0.0498],\n",
      "         [1.0000, 1.0000, 1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "exp_res = torch.exp(diff)\n",
    "print(exp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0523, 1.0523, 1.0523]],\n",
      "\n",
      "        [[1.0523, 1.0523, 1.0523]],\n",
      "\n",
      "        [[1.0523, 1.0523, 1.0523]]]) torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "sum_res = torch.sum(exp_res, dim=1, keepdim=True)\n",
    "print(sum_res, sum_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0024, 0.0024, 0.0024],\n",
      "         [0.0473, 0.0473, 0.0473],\n",
      "         [0.9503, 0.9503, 0.9503]],\n",
      "\n",
      "        [[0.0024, 0.0024, 0.0024],\n",
      "         [0.0473, 0.0473, 0.0473],\n",
      "         [0.9503, 0.9503, 0.9503]],\n",
      "\n",
      "        [[0.0024, 0.0024, 0.0024],\n",
      "         [0.0473, 0.0473, 0.0473],\n",
      "         [0.9503, 0.9503, 0.9503]]])\n",
      "tensor([[[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "softmax = exp_res / sum_res\n",
    "print(softmax)\n",
    "print(torch.sum(softmax, dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimåç¼©-å†…å­˜å¸ƒå±€\n",
    "\n",
    "Note: dim=0 æ˜¯æœ€å¤–å±‚ size=4ï¼ˆå¦‚ä¸‹æ‰€ç¤ºï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [[1, 2], [3, 4], [8, 9]],    # å±‚0\n",
    "    [[5, 6], [7, 8], [1, 2]],     # å±‚1\n",
    "    [[5, 6], [7, 8], [1, 2]],\n",
    "    [[5, 6], [7, 8], [1, 2]]\n",
    "]) \n",
    "\n",
    "x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [8, 9]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x[0])\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim=0 (å‹æ‰å±‚): tensor([[5, 6],\n",
      "        [7, 8],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(\"dim=0 (å‹æ‰å±‚):\", torch.max(x, dim=0).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ©ç \n",
    "\n",
    "- ã€é—®é¢˜ã€‘Pytorchï¼Œä¸€ä¸ªçŸ©é˜µã€å’Œæ©ç çŸ©é˜µï¼ˆtrueã€falseï¼‰ã€‚å¦‚ä½•è®©trueçš„ä½ç½®ä¸å˜ï¼Œfalseçš„è®¾ç½®ä¸ºæŸä¸ªå€¼ï¼Ÿ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False],\n",
      "        [ True, False]])\n",
      "tensor([[   0., -100.],\n",
      "        [   2., -100.]])\n",
      "tensor([[-100.,    1.],\n",
      "        [-100.,    3.]])\n",
      "tensor([[   0., -100.],\n",
      "        [   2., -100.]])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.arange(4, dtype=torch.float32).reshape((2, 2))\n",
    "masks = torch.tensor([[True, False], [True, False]], dtype=torch.bool)\n",
    "print(masks)\n",
    "print(torch.where(masks, arr, -100))\n",
    "print(arr.masked_fill(masks, -100))\n",
    "print(arr.masked_fill(~masks, -100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "è¡¥å……è¯´æ˜\n",
    "-   è‹¥éœ€**åŸåœ°ä¿®æ”¹**ï¼ˆèŠ‚çœå†…å­˜ï¼‰ï¼š\n",
    "-   æ©ç å½¢çŠ¶éœ€ä¸åŸå¼ é‡**å¯å¹¿æ’­å…¼å®¹**ï¼ˆå¦‚ `(3,4)` å¼ é‡å¯ç”¨ `(3,1)` æ©ç ï¼‰\n",
    "-   æ‰€æœ‰æ–¹æ³•å‡æ”¯æŒ GPU å¼ é‡ï¼Œæ— éœ€é¢å¤–å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "tensor([[0., nan],\n",
      "        [2., nan]])\n"
     ]
    }
   ],
   "source": [
    "print(arr)\n",
    "arr[~masks] = torch.nan\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf],\n",
      "        [2., -inf]])\n",
      "tensor([[0., inf],\n",
      "        [2., inf]])\n"
     ]
    }
   ],
   "source": [
    "print(arr)\n",
    "arr[~masks] = torch.inf\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1],\n",
      "          [ 2,  3]],\n",
      "\n",
      "         [[ 4,  5],\n",
      "          [ 6,  7]]],\n",
      "\n",
      "\n",
      "        [[[ 8,  9],\n",
      "          [10, 11]],\n",
      "\n",
      "         [[12, 13],\n",
      "          [14, 15]]]])\n",
      "tensor([[12, 13],\n",
      "        [14, 15]])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.arange(16).reshape((2, 2, 2, 2))\n",
    "print(arr)\n",
    "print(arr[1, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  2],\n",
      "          [ 1,  3]],\n",
      "\n",
      "         [[ 4,  6],\n",
      "          [ 5,  7]]],\n",
      "\n",
      "\n",
      "        [[[ 8, 10],\n",
      "          [ 9, 11]],\n",
      "\n",
      "         [[12, 14],\n",
      "          [13, 15]]]])\n",
      "tensor([[12, 14],\n",
      "        [13, 15]])\n"
     ]
    }
   ],
   "source": [
    "res = arr.transpose(-2, -1)\n",
    "print(res)\n",
    "print(res[1, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.arange(6).reshape((2, 3))\n",
    "print(arr)\n",
    "res = arr.transpose(-2, -1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å› æœæ©ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False],\n",
       "        [ True,  True, False, False, False],\n",
       "        [ True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 5\n",
    "ones = torch.ones(seq_len, seq_len)\n",
    "mask = torch.tril(ones)\n",
    "print(mask)\n",
    "mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€šè¿‡ â€œå¹¿æ’­æ¯”è¾ƒâ€ åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = torch.arange(seq_len)\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False],\n",
       "        [ True,  True, False, False, False],\n",
       "        [ True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = positions.unsqueeze(0) <= positions.unsqueeze(1)\n",
    "mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
