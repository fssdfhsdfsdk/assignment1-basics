{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¹¿æ’­\n",
    "\n",
    "ã€æˆ‘çš„ç†è§£ã€‘\n",
    "nç»´å¼ é‡A, Bçš„çŸ©é˜µä¹˜æ³•ï¼Œè¦æ±‚å‰é¢ n-2 ç»´éƒ½ç›¸ç­‰, æœ€åŽ2ä¸ªç»´åº¦å¿…é¡»æ˜¯ (m, n), (n, k) çš„ç¬¦åˆçŸ©é˜µä¹˜æ³•çš„è¦æ±‚\n",
    " - ã€é”™è¯¯ç‚¹ã€‘å‰é¢çš„ç»´åº¦ï¼ˆå³ batch ç»´åº¦ï¼‰éœ€è¦æ»¡è¶³å¹¿æ’­ï¼ˆbroadcastingï¼‰è§„åˆ™ï¼Œè€Œä¸ä»…ä»…æ˜¯â€œå®Œå…¨ç›¸ç­‰â€ã€‚\n",
    "\n",
    "ã€ç†è§£2ã€‘å¹¿æ’­è§„åˆ™ï¼Œåˆ™å¯¹åº”çš„ç»´åº¦å¿…é¡»æ˜¯æ•´æ•°å€ï¼Œå¦åˆ™ä¸èƒ½å¹¿æ’­ï¼Ÿ\n",
    " - ã€é”™è¯¯ç‚¹ã€‘å¹¿æ’­çœ‹çš„æ˜¯â€œç›¸ç­‰æˆ–ä¸º1â€ï¼Œè€Œä¸æ˜¯â€œæ•´æ•°å€â€\n",
    "\n",
    "| æƒ…å†µ                   | èƒ½å¦å¹¿æ’­ï¼Ÿ | åŽŸå›                      |\n",
    "| -------------------- | ----- | ---------------------- |\n",
    "| `(3, 4)` vs `(3, 4)` | âœ…     | ç›¸ç­‰                     |\n",
    "| `(1, 4)` vs `(3, 4)` | âœ…     | 1 å¯æ‰©å±•                  |\n",
    "| `(2, 6)` vs `(3, 6)` | âŒ     | 2â‰ 3 ä¸”æ—  1               |\n",
    "| `(4, 5)` vs `(2, 5)` | âŒ     | 4â‰ 2 ä¸”æ—  1ï¼ˆå³ä½¿ 4 æ˜¯ 2 çš„å€æ•°ï¼‰ |\n",
    "\n",
    "\n",
    "ã€é—®é¢˜ã€‘ä¸ºä»€ä¹ˆä¸èƒ½ï¼Ÿ\n",
    "\n",
    "\n",
    "|ä½ çš„æƒ³æ³•|å®žé™…è§„åˆ™|åŽŸå› |\n",
    "|---|---|---|\n",
    "|â€œ(2,5) é‡å¤ä¸€æ¬¡å˜ (4,5)â€|âŒ ä¸å…è®¸|å¹¿æ’­åªå…è®¸æ²¿ **size=1** çš„ç»´åº¦æ‹‰ä¼¸|\n",
    "|å¹¿æ’­ = ä»»æ„é‡å¤|âŒ|å¹¿æ’­ = **æ— æ­§ä¹‰ã€ç¡®å®šæ€§çš„è™šæ‹Ÿå¤åˆ¶**|\n",
    "|æ•´æ•°å€å°±èƒ½å¹¿æ’­|âŒ|å¿…é¡»æ»¡è¶³ï¼š**ç›¸ç­‰ æˆ– å…¶ä¸­ä¸€ä¸ªæ˜¯ 1**|\n",
    "\n",
    "> ðŸ’¡ **è®°ä½**ï¼šå¹¿æ’­æ˜¯ä¸ºäº†æ–¹ä¾¿â€œæ ‡é‡/å‘é‡/çŸ©é˜µâ€ä¸Žé«˜ç»´å¼ é‡è¿ç®—ï¼Œ**ä¸æ˜¯ä¸ºäº†ä»»æ„å½¢çŠ¶çš„è‡ªåŠ¨é€‚é…**ã€‚å½“éœ€è¦éžæ ‡å‡†å¯¹é½æ—¶ï¼Œè¯·æ˜¾å¼ä½¿ç”¨ `repeat`ã€`expand`ã€`reshape` ç­‰æ“ä½œã€‚\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0204, -1.5683, -0.6974],\n",
      "        [ 1.2406,  0.5915,  0.8927]])\n",
      "tensor([[-2.0204, -1.5683, -0.6974],\n",
      "        [ 1.2406,  0.5915,  0.8927]])\n",
      "tensor([[-2.0204, -1.5683, -0.6974],\n",
      "        [ 1.2406,  0.5915,  0.8927]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "A = torch.randn(2, 3, 4)\n",
    "B = torch.randn(2, 4, 5)\n",
    "\n",
    "# æ–¹æ³•1: torch.einsum\n",
    "C1 = torch.einsum('bij,bjk->bi', A, B)  # å…ˆä¹˜å†å¯¹ k æ±‚å’Œ\n",
    "print(C1)\n",
    "\n",
    "# æ–¹æ³•2: einopsï¼ˆéœ€ç»„åˆï¼‰\n",
    "from einops import einsum\n",
    "C2 = einsum(A, B, 'b i j, b j k -> b i')  # einops ä¹Ÿæ”¯æŒ einsum!\n",
    "print(C2)\n",
    "\n",
    "# æ–¹æ³•3: åŽŸç”Ÿ\n",
    "C3 = (A @ B).sum(dim=-1)\n",
    "print(C3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾‹å­1: æ‰¹é‡çŸ©é˜µä¹˜æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 4])\n",
      "torch.Size([10, 20, 4])\n",
      "torch.Size([10, 20, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n",
    "\n",
    "batch = 10\n",
    "seq_len = 20\n",
    "d_in = 5\n",
    "d_out = 4\n",
    "D = torch.randn(batch, seq_len, d_in)\n",
    "A = torch.randn(d_out, d_in)\n",
    "\n",
    "Y = D @ A.T\n",
    "\n",
    "assert Y.shape == (batch, seq_len, d_out)\n",
    "print(Y.shape)\n",
    "\n",
    "Y = einsum(D, A, \"batch seq_len d_in, d_out d_in -> batch seq_len d_out\")\n",
    "print(Y.shape)\n",
    "\n",
    "Y = einsum(D, A, \"... d_in, d_out d_in -> ... d_out\")\n",
    "print(Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾‹å­2ï¼šå¹¿æ’­æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([64, 10, 128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, einsum\n",
    "\n",
    "images = torch.randn(64, 128, 128, 3) # (batch, height, width, channel)\n",
    "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)\n",
    "\n",
    "## Reshape and multiply  \n",
    "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")  \n",
    "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")  \n",
    "dimmed_images = images_rearr * dim_value\n",
    "\n",
    "## Or in one go:\n",
    "dimmed_images2 = einsum(\n",
    "    images, dim_by,\n",
    "    \"batch height width channel, dim_value -> batch dim_value height width channel\"\n",
    ")\n",
    "\n",
    "print(torch.equal(dimmed_images, dimmed_images2))\n",
    "print(dimmed_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾‹å­3ï¼šåƒç´ æ··åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç´¢å¼•\n",
    "\n",
    "PyTorch æ”¯æŒå¤šç§ç´¢å¼•æ–¹å¼ï¼Œä¸»è¦åŒ…æ‹¬ï¼š\n",
    "\n",
    "1. **åŸºæœ¬åˆ‡ç‰‡ï¼ˆBasic Slicingï¼‰**\n",
    "    - ä½¿ç”¨ `:`ã€æ•´æ•°ã€`...` ç­‰ã€‚\n",
    "    - è¿”å›žçš„æ˜¯åŽŸå¼ é‡çš„**è§†å›¾ï¼ˆviewï¼‰**ï¼Œä¸å¤åˆ¶æ•°æ®ã€‚\n",
    "    - ä¾‹å¦‚ï¼š`t[0]`, `t[:, 1:3]`\n",
    "2. **é«˜çº§ç´¢å¼•ï¼ˆAdvanced Indexingï¼‰**\n",
    "    - ä½¿ç”¨ **æ•´æ•°åˆ—è¡¨/æ•°ç»„** æˆ– **å¸ƒå°”æŽ©ç **ã€‚\n",
    "    - è¿”å›žçš„æ˜¯**æ–°å¼ é‡ï¼ˆå‰¯æœ¬ï¼‰**ï¼Œä¼šå¤åˆ¶æ•°æ®ã€‚\n",
    "    - ä¾‹å¦‚ï¼š`t[[0, 2]]`, `t[torch.tensor([0,2])]`\n",
    "\n",
    "> âš ï¸ æ³¨æ„ï¼šå½“ä½ ç”¨ `torch.LongTensor([0, 2])` è¿™æ ·çš„å¼ é‡ä½œä¸ºç´¢å¼•æ—¶ï¼Œå°±è¿›å…¥äº†**é«˜çº§ç´¢å¼•**çš„èŒƒç•´ã€‚\n",
    "\n",
    "`indices` æ˜¯ä¸€ä¸ªä¸€ç»´ LongTensorï¼ŒPyTorch é»˜è®¤å°†å…¶ç”¨äºŽç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆdim=0ï¼‰ã€‚\n",
    "æ‰€ä»¥å®ƒä¼šå–å‡ºç¬¬ 0 è¡Œå’Œç¬¬ 2 è¡Œã€‚\n",
    "\n",
    "ðŸ“Œ **å…³é”®ç‚¹**ï¼š`t1[indices]` å®žé™…ä¸Šæ˜¯ `t1[indices, :]` çš„ç®€å†™ï¼ˆçœç•¥äº†åŽé¢çš„ `:`ï¼‰ã€‚\n",
    "\n",
    "æ³¨æ„ï¼š\n",
    "\n",
    "- `t1[indices]` æ˜¯ Python çš„ `__getitem__` è¯­æ³•ç³–ï¼Œæ›´ç®€æ´ã€‚\n",
    "- `index_select` æ›´**æ˜¾å¼ã€å®‰å…¨ã€å¯è¯»æ€§å¼º**ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯ä¸­æŽ¨èä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  2],\n",
      "        [ 4,  6],\n",
      "        [ 8, 10]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  2],\n",
      "        [ 4,  6],\n",
      "        [ 8, 10]])\n",
      "tensor([ 0, 10])\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.arange(12).reshape((3, 4))\n",
    "indices = torch.LongTensor([0, 2])\n",
    "\n",
    "print(t1[indices])\n",
    "print(t1[:, indices])\n",
    "print(torch.index_select(t1, 0, indices))\n",
    "print(torch.index_select(t1, 1, indices))\n",
    "\n",
    "# ä½†æ³¨æ„ï¼šä¸èƒ½ç›´æŽ¥å†™ t1[indices, indices]ï¼\n",
    "# å› ä¸ºè¿™ä¼šè§¦å‘â€œå¹¿æ’­å¼é«˜çº§ç´¢å¼•â€ï¼Œç»“æžœæ˜¯ (2,) è€Œä¸æ˜¯ (2,2)\n",
    "print(t1[indices, indices])  # è¾“å‡º:  â† åªå– (0,0) å’Œ (2,2)\n",
    "print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 8,  9, 10, 11]]) torch.Size([5, 4])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 8,  9, 10, 11]]) torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "res = t1[[1, 0, 1, 2, 2]]\n",
    "print(res, res.shape)\n",
    "res = t1[[1, 0, 1, 2, 2],:]  # ç­‰ä»·è¡¨è¾¾å¼, ä»Žç¬¬0ç»´ é€‰æ‹©å¤šä¸ªè¡Œ\n",
    "print(res, res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]]) t1\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[ 0,  1,  2,  3],\n",
      "         [ 8,  9, 10, 11]]]) torch.Size([2, 2, 4])\n",
      "tensor([[0, 9],\n",
      "        [0, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(t1, \"t1\")\n",
    "idx2 = torch.LongTensor([[0, 2], [0, 2]])\n",
    "res2 = t1[idx2]\n",
    "print(res2, res2.shape)\n",
    "print(torch.gather(t1, dim=0, index=idx2))\n",
    "# take_along_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™æ˜¯ä¸€ä¸ªéžå¸¸ç»å…¸çš„Â **é«˜çº§ç´¢å¼•ï¼ˆAdvanced Indexingï¼‰**Â æ¡ˆä¾‹ã€‚åœ¨ 2026 å¹´çš„ PyTorch ç‰ˆæœ¬ä¸­ï¼Œå…¶é€»è¾‘ä¾ç„¶éµå¾ª NumPy çš„å¹¿æ’­è§„åˆ™ã€‚\n",
    "\n",
    "ä¸ºä»€ä¹ˆç»“æžœæ˜¯Â `[2, 2, 4]`ï¼Ÿ\n",
    "\n",
    "å½“ä½ å¯¹ä¸€ä¸ª 2D å¼ é‡Â `t1`Â ä½¿ç”¨ä¸€ä¸ª 2D ç´¢å¼•å¼ é‡Â `idx2`Â æ—¶ï¼ŒPyTorch çš„å¤„ç†é€»è¾‘å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. **ç´¢å¼•å±‚çº§å®šä½**ï¼šä½ åªæä¾›äº†ä¸€ä¸ªç´¢å¼•å¼ é‡Â `idx2`ï¼Œå› æ­¤ PyTorch å°†å…¶ä½œç”¨äºŽÂ `t1`Â çš„**ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆDim 0ï¼Œå³â€œè¡Œâ€ï¼‰**Â [1]ã€‚\n",
    "2. **å½¢çŠ¶æ˜ å°„**ï¼š\n",
    "    - `t1`Â çš„å½¢çŠ¶æ˜¯Â `(3, 4)`ã€‚å…¶ä¸­Â `dim 0`Â å¤§å°ä¸º 3ï¼Œ`dim 1`Â å¤§å°ä¸º 4ã€‚\n",
    "    - `idx2`Â çš„å½¢çŠ¶æ˜¯Â `(2, 2)`ã€‚\n",
    "3. **å…ƒç´ æ›¿æ¢**ï¼š\n",
    "    - PyTorch ä¼šéåŽ†Â `idx2`Â ä¸­çš„æ¯ä¸€ä¸ªå€¼ï¼Œå°†å…¶æ›¿æ¢ä¸ºÂ `t1`Â ä¸­å¯¹åº”çš„â€œè¡Œâ€ã€‚\n",
    "    - `idx2`Â ä¸­çš„å…ƒç´ æ˜¯Â `0`Â å’ŒÂ `2`ã€‚åœ¨Â `t1`Â ä¸­ï¼Œç¬¬ 0 è¡Œæ˜¯Â `[0, 1, 2, 3]`ï¼Œç¬¬ 2 è¡Œæ˜¯Â `[8, 9, 10, 11]`ã€‚\n",
    "4. **æœ€ç»ˆå½¢çŠ¶è®¡ç®—**ï¼š\n",
    "    - ç»“æžœçš„å‰ä¸¤ä¸ªç»´åº¦ç”±Â **ç´¢å¼•å¼ é‡Â `idx2`Â çš„å½¢çŠ¶**Â å†³å®šï¼š`(2, 2)`ã€‚\n",
    "    - ç»“æžœçš„å‰©ä½™ç»´åº¦ç”±Â **è¢«ç´¢å¼•å¼ é‡Â `t1`Â å‰©ä½™çš„ç»´åº¦**Â å†³å®šï¼š`(4,)`ã€‚\n",
    "    - å› æ­¤ï¼Œæœ€ç»ˆå½¢çŠ¶ä¸ºÂ `(2, 2, 4)`ã€‚\n",
    "\n",
    "å†…éƒ¨å¯¹åº”å…³ç³»æ‹†è§£ï¼š\n",
    "\n",
    "- `res2[0, 0]`Â å¯¹åº”Â `t1[idx2[0, 0]]`Â ->Â `t1[0]`Â ->Â `[0, 1, 2, 3]`\n",
    "- `res2[0, 1]`Â å¯¹åº”Â `t1[idx2[0, 1]]`Â ->Â `t1[2]`Â ->Â `[8, 9, 10, 11]`\n",
    "- `res2[1, 0]`Â å¯¹åº”Â `t1[idx2[1, 0]]`Â ->Â `t1[0]`Â ->Â `[0, 1, 2, 3]`\n",
    "- `res2[1, 1]`Â å¯¹åº”Â `t1[idx2[1, 1]]`Â ->Â `t1[2]`Â ->Â `[8, 9, 10, 11]`\n",
    "\n",
    "å¦‚æžœä½ æƒ³å¾—åˆ°Â `(2, 2)`Â è€Œä¸æ˜¯Â `(2, 2, 4)`Â æ€Žä¹ˆåŠžï¼Ÿ\n",
    "\n",
    "å¦‚æžœä½ å¸Œæœ›ç»“æžœç›´æŽ¥å®šä½åˆ°å…·ä½“çš„æ ‡é‡å…ƒç´ ï¼Œä½ éœ€è¦åŒæ—¶æä¾›Â **Dim 1ï¼ˆåˆ—ï¼‰**Â çš„ç´¢å¼•ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå¦‚æžœä½ æƒ³åœ¨Â `t1`Â ä¸­æ ¹æ®Â `idx2`Â æå–ç‰¹å®šçš„å…ƒç´ ï¼Œä½ éœ€è¦è®©ç´¢å¼•å¼ é‡çš„å½¢çŠ¶åŒ¹é…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 10],\n",
      "        [ 0, 10]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# å‡è®¾æˆ‘ä»¬è¦æå– (0,0), (2,2) å’Œ (0,0), (2,2) ä½ç½®çš„å››ä¸ªå…ƒç´ \n",
    "row_idx = torch.LongTensor([[0, 2], [0, 2]])\n",
    "col_idx = torch.LongTensor([[0, 2], [0, 2]])\n",
    "\n",
    "res = t1[row_idx, col_idx] \n",
    "print(res, res.shape) # è¾“å‡º torch.Size([2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Dimensions (Coordinate Indexing): When multiple integer index tensors are provided, they broadcast together to form a set of coordinates. The resulting tensor's shape will be the broadcasted shape of the index tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 11])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "# x:\n",
    "# tensor([[ 0,  1,  2,  3],\n",
    "#         [ 4,  5,  6,  7],\n",
    "#         [ 8,  9, 10, 11]])\n",
    "\n",
    "rows = torch.tensor([0, 2])\n",
    "cols = torch.tensor([1, 3])\n",
    "# Select elements at (0, 1) and (2, 3)\n",
    "selected = x[rows, cols]\n",
    "# selected is tensor([1, 11])\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Tensor Indexing\n",
    "\n",
    "You can use a BoolTensor as a mask to select elements corresponding to True values. \n",
    " - The boolean tensor must have the same shape as the original tensor (or be broadcastable) in the dimensions being masked. The output is a 1D tensor containing all the selected elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).reshape(2, 2)\n",
    "# x:\n",
    "# tensor([[0, 1],\n",
    "#         [2, 3]])\n",
    "\n",
    "mask = torch.tensor([[True, False], [False, True]])\n",
    "selected = x[mask]\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4119, -0.4434,  0.4310],\n",
      "        [ 0.3909, -0.2405,  0.0515]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones((2, 3))\n",
    "torch.nn.init.trunc_normal_(t1, a=-0.5, b=0.5)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.tensor(9.0)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "weight1 = torch.randn(2, 3)\n",
    "print(weight1.requires_grad)\n",
    "\n",
    "weight2 = nn.Parameter(torch.randn(2, 3))\n",
    "print(weight2.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹ é¢˜ï¼šé«˜çº§ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_ids torch.Size([40])\n",
      "flat_ids torch.Size([4])\n",
      "å¼‚å¸¸index token idï¼ŒæŠ›å¼‚å¸¸ç¬¦åˆè¡Œä¸ºã€‚ index out of range in self\n",
      "âœ… æ­å–œï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ‚¨å·²æŽŒæ¡é«˜çº§ç´¢å¼•ç²¾é«“\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NaiveEmbedding(nn.Module):\n",
    "    \"\"\"ç¹çå†™æ³•ï¼šä½¿ç”¨ index_select + reshape\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embed_matrix = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "    \n",
    "    def forward(self, token_ids):\n",
    "        # TODO: å®žçŽ° index_select çš„ç¹çå†™æ³•ï¼ˆ4æ­¥ï¼‰\n",
    "        # 1. ä¿å­˜åŽŸå§‹å½¢çŠ¶ï¼ˆé™¤æœ€åŽä¸€ç»´å¤–ï¼‰\n",
    "        original_shape = token_ids.shape\n",
    "        \n",
    "        # 2. å°† token_ids å±•å¹³ä¸º 1D\n",
    "        flat_ids = token_ids.reshape(-1)\n",
    "        print(\"flat_ids\", flat_ids.shape)\n",
    "        \n",
    "        # 3. ä½¿ç”¨ index_select æå–å‘é‡ï¼ˆæ³¨æ„ï¼šindex_select è¦æ±‚ç´¢å¼•ä¸º1Dï¼‰\n",
    "        flat_embeds = torch.index_select(self.embed_matrix, 0, flat_ids)\n",
    "        \n",
    "        # 4. æ¢å¤å½¢çŠ¶ï¼šåŽŸå§‹å½¢çŠ¶ + (embed_dim,)\n",
    "        new_shape = original_shape + (flat_embeds.shape[-1], )\n",
    "        return flat_embeds.reshape(new_shape) # â† ç”¨æˆ·å¡«å†™\n",
    "\n",
    "\n",
    "class OptimizedEmbedding(nn.Module):\n",
    "    \"\"\"ç®€æ´å†™æ³•ï¼šç›´æŽ¥ä½¿ç”¨é«˜çº§ç´¢å¼•\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embed_matrix = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "    \n",
    "    def forward(self, token_ids):\n",
    "        # TODO: ç”¨ä¸€è¡Œä»£ç å®žçŽ° embedding lookup\n",
    "        return self.embed_matrix[token_ids]\n",
    "\n",
    "\n",
    "# ==================== æµ‹è¯•æ¡†æž¶ï¼ˆæœªå¡«å†™æ ¸å¿ƒé€»è¾‘æ—¶å¿…ç„¶å¤±è´¥ï¼‰ ====================\n",
    "def test_embedding_consistency():\n",
    "    vocab_size, embed_dim = 100, 64\n",
    "    naive_emb = NaiveEmbedding(vocab_size, embed_dim)\n",
    "    opt_emb = OptimizedEmbedding(vocab_size, embed_dim)\n",
    "    opt_emb.embed_matrix.data = naive_emb.embed_matrix.data.clone()\n",
    "    \n",
    "    # æµ‹è¯•1: 2D å¼ é‡ [batch, seq_len]\n",
    "    token_ids_2d = torch.randint(0, vocab_size, (4, 10))\n",
    "    \n",
    "    # æœªå¡«å†™æ—¶ï¼šnaive_emb è¿”å›ž None â†’ è§¦å‘ TypeError\n",
    "    naive_out = naive_emb(token_ids_2d)  # â† å¿…ç„¶å¤±è´¥ï¼ç”¨æˆ·éœ€å®žçŽ°\n",
    "    opt_out = opt_emb(token_ids_2d)      # â† å¿…ç„¶å¤±è´¥ï¼ç”¨æˆ·éœ€å®žçŽ°\n",
    "    \n",
    "    # ä»¥ä¸‹æ–­è¨€ä»…åœ¨ç”¨æˆ·æ­£ç¡®å®žçŽ°åŽé€šè¿‡\n",
    "    assert naive_out is not None, \"âŒ NaiveEmbedding æœªå®žçŽ°ï¼\"\n",
    "    assert opt_out is not None, \"âŒ OptimizedEmbedding æœªå®žçŽ°ï¼\"\n",
    "    assert torch.allclose(naive_out, opt_out), \"âŒ è¾“å‡ºä¸ä¸€è‡´ï¼\"\n",
    "    assert opt_out.shape == (4, 10, embed_dim), f\"âŒ å½¢çŠ¶é”™è¯¯: {opt_out.shape}\"\n",
    "    \n",
    "    # æµ‹è¯•2: 3D å¼ é‡éªŒè¯å½¢çŠ¶ä¼ æ’­\n",
    "    token_ids_3d = torch.randint(0, vocab_size, (2, 5, 3))\n",
    "    output = opt_emb(token_ids_3d)\n",
    "    assert output.shape == (2, 5, 3, embed_dim), f\"âŒ 3Då½¢çŠ¶é”™è¯¯: {output.shape}\"\n",
    "    \n",
    "    # é™„åŠ æŒ‘æˆ˜ï¼šè´Ÿæ•°ç´¢å¼•ï¼ˆä»… OptimizedEmbedding æ”¯æŒï¼‰\n",
    "    neg_ids = torch.tensor([[-1, 0], [1, -2]])  # -1 è¡¨ç¤ºæœ€åŽä¸€ä¸ªå…ƒç´ \n",
    "    try:\n",
    "        naive_emb(neg_ids)  # åº”æŠ›å‡º RuntimeErrorï¼ˆindex_select ä¸æ”¯æŒè´Ÿç´¢å¼•ï¼‰\n",
    "        raise AssertionError(\"âŒ NaiveEmbedding åº”æ‹’ç»è´Ÿç´¢å¼•ï¼\")\n",
    "    except Exception as e:\n",
    "        print(\"å¼‚å¸¸index token idï¼ŒæŠ›å¼‚å¸¸ç¬¦åˆè¡Œä¸ºã€‚\", str(e))\n",
    "        pass  # é¢„æœŸè¡Œä¸º\n",
    "    \n",
    "    # OptimizedEmbedding åº”æ­£ç¡®å¤„ç†è´Ÿç´¢å¼•\n",
    "    neg_out = opt_emb(neg_ids)\n",
    "    assert neg_out.shape == (2, 2, embed_dim), \"âŒ è´Ÿç´¢å¼•è¾“å‡ºå½¢çŠ¶é”™è¯¯\"\n",
    "    # éªŒè¯ -1 ç¡®å®žæŒ‡å‘æœ€åŽä¸€ä¸ªå…ƒç´ \n",
    "    assert torch.allclose(neg_out[0,0], opt_emb.embed_matrix[-1]), \"âŒ è´Ÿç´¢å¼•é€»è¾‘é”™è¯¯\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        test_embedding_consistency()\n",
    "        print(\"âœ… æ­å–œï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ‚¨å·²æŽŒæ¡é«˜çº§ç´¢å¼•ç²¾é«“\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc() \n",
    "        print(f\"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}: {e}\")\n",
    "        print(\"\\nðŸ’¡ æç¤ºï¼šè¯·å®Œæˆä»¥ä¸‹æ ¸å¿ƒå®žçŽ°ï¼š\")\n",
    "        print(\"  1. NaiveEmbedding.forward() ä¸­çš„ 4 æ­¥ reshape + index_select\")\n",
    "        print(\"  2. OptimizedEmbedding.forward() ä¸­çš„å•è¡Œé«˜çº§ç´¢å¼•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keepdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022) torch.Size([])\n",
      "torch.Size([64, 128]) torch.Size([64, 128, 1])\n"
     ]
    }
   ],
   "source": [
    "images = torch.randn(64, 128, 3)\n",
    "res0 = torch.mean(images)\n",
    "res1 = torch.mean(images, dim=2)\n",
    "res2 = torch.mean(images, dim=2, keepdim=True)\n",
    "\n",
    "print(res0, res0.shape)\n",
    "print(res1.shape, res2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (128) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mres1\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (128) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "images - res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "print((images - res2).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
